{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wonderland_training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6i8cmhFiX9X",
        "colab_type": "code",
        "outputId": "563c6516-63ff-4caa-f7ad-1a15fb53afcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "print(\"Hello\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Hello\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULFno_T1iYgw",
        "colab_type": "code",
        "outputId": "d1094d6e-3303-4cce-eb6c-63b4761bb565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "! git clone https://github.com/whopriyam/NLP-Practice"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NLP-Practice'...\n",
            "remote: Enumerating objects: 122, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/122)\u001b[K\rremote: Counting objects:   1% (2/122)\u001b[K\rremote: Counting objects:   2% (3/122)\u001b[K\rremote: Counting objects:   3% (4/122)\u001b[K\rremote: Counting objects:   4% (5/122)\u001b[K\rremote: Counting objects:   5% (7/122)\u001b[K\rremote: Counting objects:   6% (8/122)\u001b[K\rremote: Counting objects:   7% (9/122)\u001b[K\rremote: Counting objects:   8% (10/122)\u001b[K\rremote: Counting objects:   9% (11/122)\u001b[K\rremote: Counting objects:  10% (13/122)\u001b[K\rremote: Counting objects:  11% (14/122)\u001b[K\rremote: Counting objects:  12% (15/122)\u001b[K\rremote: Counting objects:  13% (16/122)\u001b[K\rremote: Counting objects:  14% (18/122)\u001b[K\rremote: Counting objects:  15% (19/122)\u001b[K\rremote: Counting objects:  16% (20/122)\u001b[K\rremote: Counting objects:  17% (21/122)\u001b[K\rremote: Counting objects:  18% (22/122)\u001b[K\rremote: Counting objects:  19% (24/122)\u001b[K\rremote: Counting objects:  20% (25/122)\u001b[K\rremote: Counting objects:  21% (26/122)\u001b[K\rremote: Counting objects:  22% (27/122)\u001b[K\rremote: Counting objects:  23% (29/122)\u001b[K\rremote: Counting objects:  24% (30/122)\u001b[K\rremote: Counting objects:  25% (31/122)\u001b[K\rremote: Counting objects:  26% (32/122)\u001b[K\rremote: Counting objects:  27% (33/122)\u001b[K\rremote: Counting objects:  28% (35/122)\u001b[K\rremote: Counting objects:  29% (36/122)\u001b[K\rremote: Counting objects:  30% (37/122)\u001b[K\rremote: Counting objects:  31% (38/122)\u001b[K\rremote: Counting objects:  32% (40/122)\u001b[K\rremote: Counting objects:  33% (41/122)\u001b[K\rremote: Counting objects:  34% (42/122)\u001b[K\rremote: Counting objects:  35% (43/122)\u001b[K\rremote: Counting objects:  36% (44/122)\u001b[K\rremote: Counting objects:  37% (46/122)\u001b[K\rremote: Counting objects:  38% (47/122)\u001b[K\rremote: Counting objects:  39% (48/122)\u001b[K\rremote: Counting objects:  40% (49/122)\u001b[K\rremote: Counting objects:  41% (51/122)\u001b[K\rremote: Counting objects:  42% (52/122)\u001b[K\rremote: Counting objects:  43% (53/122)\u001b[K\rremote: Counting objects:  44% (54/122)\u001b[K\rremote: Counting objects:  45% (55/122)\u001b[K\rremote: Counting objects:  46% (57/122)\u001b[K\rremote: Counting objects:  47% (58/122)\u001b[K\rremote: Counting objects:  48% (59/122)\u001b[K\rremote: Counting objects:  49% (60/122)\u001b[K\rremote: Counting objects:  50% (61/122)\u001b[K\rremote: Counting objects:  51% (63/122)\u001b[K\rremote: Counting objects:  52% (64/122)\u001b[K\rremote: Counting objects:  53% (65/122)\u001b[K\rremote: Counting objects:  54% (66/122)\u001b[K\rremote: Counting objects:  55% (68/122)\u001b[K\rremote: Counting objects:  56% (69/122)\u001b[K\rremote: Counting objects:  57% (70/122)\u001b[K\rremote: Counting objects:  58% (71/122)\u001b[K\rremote: Counting objects:  59% (72/122)\u001b[K\rremote: Counting objects:  60% (74/122)\u001b[K\rremote: Counting objects:  61% (75/122)\u001b[K\rremote: Counting objects:  62% (76/122)\u001b[K\rremote: Counting objects:  63% (77/122)\u001b[K\rremote: Counting objects:  64% (79/122)\u001b[K\rremote: Counting objects:  65% (80/122)\u001b[K\rremote: Counting objects:  66% (81/122)\u001b[K\rremote: Counting objects:  67% (82/122)\u001b[K\rremote: Counting objects:  68% (83/122)\u001b[K\rremote: Counting objects:  69% (85/122)\u001b[K\rremote: Counting objects:  70% (86/122)\u001b[K\rremote: Counting objects:  71% (87/122)\u001b[K\rremote: Counting objects:  72% (88/122)\u001b[K\rremote: Counting objects:  73% (90/122)\u001b[K\rremote: Counting objects:  74% (91/122)\u001b[K\rremote: Counting objects:  75% (92/122)\u001b[K\rremote: Counting objects:  76% (93/122)\u001b[K\rremote: Counting objects:  77% (94/122)\u001b[K\rremote: Counting objects:  78% (96/122)\u001b[K\rremote: Counting objects:  79% (97/122)\u001b[K\rremote: Counting objects:  80% (98/122)\u001b[K\rremote: Counting objects:  81% (99/122)\u001b[K\rremote: Counting objects:  82% (101/122)\u001b[K\rremote: Counting objects:  83% (102/122)\u001b[K\rremote: Counting objects:  84% (103/122)\u001b[K\rremote: Counting objects:  85% (104/122)\u001b[K\rremote: Counting objects:  86% (105/122)\u001b[K\rremote: Counting objects:  87% (107/122)\u001b[K\rremote: Counting objects:  88% (108/122)\u001b[K\rremote: Counting objects:  89% (109/122)\u001b[K\rremote: Counting objects:  90% (110/122)\u001b[K\rremote: Counting objects:  91% (112/122)\u001b[K\rremote: Counting objects:  92% (113/122)\u001b[K\rremote: Counting objects:  93% (114/122)\u001b[K\rremote: Counting objects:  94% (115/122)\u001b[K\rremote: Counting objects:  95% (116/122)\u001b[K\rremote: Counting objects:  96% (118/122)\u001b[K\rremote: Counting objects:  97% (119/122)\u001b[K\rremote: Counting objects:  98% (120/122)\u001b[K\rremote: Counting objects:  99% (121/122)\u001b[K\rremote: Counting objects: 100% (122/122)\u001b[K\rremote: Counting objects: 100% (122/122), done.\u001b[K\n",
            "remote: Compressing objects: 100% (107/107), done.\u001b[K\n",
            "remote: Total 122 (delta 53), reused 73 (delta 15), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (122/122), 1.91 MiB | 12.08 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soQ5m92PieMq",
        "colab_type": "code",
        "outputId": "694a03cb-6823-41ee-c051-9dbd7f4bffa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mNLP-Practice\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVDeRgeeim2q",
        "colab_type": "code",
        "outputId": "26924cb3-3d73-4a6e-daef-26695db7eae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd NLP-Practice/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/NLP-Practice\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iibvxuVFiwxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load ascii text and covert to lowercase\n",
        "filename = \"alice_in_wonderland.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCaihHMwi3IQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8sSesr4i7iy",
        "colab_type": "code",
        "outputId": "ccea9d1e-def9-4aab-fe47-a596fe0454a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  148574\n",
            "Total Vocab:  46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asDb1obFjoV3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b81ca019-5623-49ba-a655-ce03aeed01a6"
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print (\"Total Patterns: \", n_patterns)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  148474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-uif913lTWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAwag3_vlWbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJmHZZcMlYQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the checkpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ig9o3LElqjV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61e8f7a3-fdda-4d03-9f87-21b1baf3da3b"
      },
      "source": [
        "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "148474/148474 [==============================] - 174s 1ms/step - loss: 2.9268\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.92682, saving model to weights-improvement-01-2.9268.hdf5\n",
            "Epoch 2/20\n",
            "148474/148474 [==============================] - 169s 1ms/step - loss: 2.6883\n",
            "\n",
            "Epoch 00002: loss improved from 2.92682 to 2.68833, saving model to weights-improvement-02-2.6883.hdf5\n",
            "Epoch 3/20\n",
            "148474/148474 [==============================] - 169s 1ms/step - loss: 2.5866\n",
            "\n",
            "Epoch 00003: loss improved from 2.68833 to 2.58663, saving model to weights-improvement-03-2.5866.hdf5\n",
            "Epoch 4/20\n",
            "148474/148474 [==============================] - 167s 1ms/step - loss: 2.5194\n",
            "\n",
            "Epoch 00004: loss improved from 2.58663 to 2.51936, saving model to weights-improvement-04-2.5194.hdf5\n",
            "Epoch 5/20\n",
            "148474/148474 [==============================] - 168s 1ms/step - loss: 2.4627\n",
            "\n",
            "Epoch 00005: loss improved from 2.51936 to 2.46271, saving model to weights-improvement-05-2.4627.hdf5\n",
            "Epoch 6/20\n",
            "148474/148474 [==============================] - 167s 1ms/step - loss: 2.4093\n",
            "\n",
            "Epoch 00006: loss improved from 2.46271 to 2.40926, saving model to weights-improvement-06-2.4093.hdf5\n",
            "Epoch 7/20\n",
            "148474/148474 [==============================] - 167s 1ms/step - loss: 2.3634\n",
            "\n",
            "Epoch 00007: loss improved from 2.40926 to 2.36338, saving model to weights-improvement-07-2.3634.hdf5\n",
            "Epoch 8/20\n",
            "148474/148474 [==============================] - 166s 1ms/step - loss: 2.3193\n",
            "\n",
            "Epoch 00008: loss improved from 2.36338 to 2.31930, saving model to weights-improvement-08-2.3193.hdf5\n",
            "Epoch 9/20\n",
            "148474/148474 [==============================] - 167s 1ms/step - loss: 2.2771\n",
            "\n",
            "Epoch 00009: loss improved from 2.31930 to 2.27710, saving model to weights-improvement-09-2.2771.hdf5\n",
            "Epoch 10/20\n",
            "148474/148474 [==============================] - 165s 1ms/step - loss: 2.2353\n",
            "\n",
            "Epoch 00010: loss improved from 2.27710 to 2.23532, saving model to weights-improvement-10-2.2353.hdf5\n",
            "Epoch 11/20\n",
            "148474/148474 [==============================] - 165s 1ms/step - loss: 2.1983\n",
            "\n",
            "Epoch 00011: loss improved from 2.23532 to 2.19827, saving model to weights-improvement-11-2.1983.hdf5\n",
            "Epoch 12/20\n",
            "148474/148474 [==============================] - 166s 1ms/step - loss: 2.1618\n",
            "\n",
            "Epoch 00012: loss improved from 2.19827 to 2.16176, saving model to weights-improvement-12-2.1618.hdf5\n",
            "Epoch 13/20\n",
            "148474/148474 [==============================] - 165s 1ms/step - loss: 2.1262\n",
            "\n",
            "Epoch 00013: loss improved from 2.16176 to 2.12616, saving model to weights-improvement-13-2.1262.hdf5\n",
            "Epoch 14/20\n",
            "148474/148474 [==============================] - 166s 1ms/step - loss: 2.0947\n",
            "\n",
            "Epoch 00014: loss improved from 2.12616 to 2.09471, saving model to weights-improvement-14-2.0947.hdf5\n",
            "Epoch 15/20\n",
            "148474/148474 [==============================] - 166s 1ms/step - loss: 2.0613\n",
            "\n",
            "Epoch 00015: loss improved from 2.09471 to 2.06133, saving model to weights-improvement-15-2.0613.hdf5\n",
            "Epoch 16/20\n",
            "148474/148474 [==============================] - 168s 1ms/step - loss: 2.0292\n",
            "\n",
            "Epoch 00016: loss improved from 2.06133 to 2.02921, saving model to weights-improvement-16-2.0292.hdf5\n",
            "Epoch 17/20\n",
            " 72704/148474 [=============>................] - ETA: 1:25 - loss: 1.9912"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SMR89KAlvvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}