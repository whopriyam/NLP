{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unicode_samples', 'mte_teip5.zip', 'indian', 'stopwords', 'brown', 'swadesh', 'mac_morpho', 'conll2002.zip', 'indian.zip', 'abc', 'comparative_sentences', 'brown_tei.zip', 'cmudict.zip', 'conll2000.zip', 'universal_treebanks_v20.zip', 'words', 'pros_cons', 'udhr2', 'nonbreaking_prefixes.zip', 'lin_thesaurus', 'webtext', 'smultron.zip', 'names', 'sentiwordnet', 'dolch.zip', 'wordnet_ic.zip', 'brown.zip', 'alpino.zip', 'panlex_swadesh.zip', 'cmudict', 'sinica_treebank.zip', 'treebank.zip', 'ptb', 'inaugural', 'ppattach.zip', 'dependency_treebank.zip', 'opinion_lexicon.zip', 'cess_esp.zip', 'product_reviews_2', 'genesis.zip', 'reuters.zip', 'conll2007.zip', 'conll2002', 'comparative_sentences.zip', 'switchboard.zip', 'cess_cat.zip', 'udhr.zip', 'subjectivity.zip', 'pl196x.zip', 'ieer', 'problem_reports', 'timit.zip', 'floresta', 'paradigms.zip', 'gazetteers.zip', 'wordnet.zip', 'inaugural.zip', 'sinica_treebank', 'stopwords.zip', 'verbnet.zip', 'gutenberg', 'ieer.zip', 'ycoe.zip', 'shakespeare.zip', 'sentence_polarity', 'framenet_v17.zip', 'kimmo.zip', 'chat80.zip', 'kimmo', 'qc.zip', 'nonbreaking_prefixes', 'senseval', 'verbnet', 'udhr2.zip', 'senseval.zip', 'chat80', 'framenet_v15.zip', 'unicode_samples.zip', 'biocreative_ppi', 'framenet_v17', 'words.zip', 'pil', 'alpino', 'omw', 'cess_cat', 'shakespeare', 'city_database', 'product_reviews_2.zip', 'abc.zip', 'europarl_raw', 'sentiwordnet.zip', 'rte.zip', 'movie_reviews', 'toolbox.zip', 'product_reviews_1.zip', 'omw.zip', 'jeita.zip', 'wordnet_ic', 'names.zip', 'conll2000', 'dependency_treebank', 'floresta.zip', 'nombank.1.0.zip', 'wordnet', 'cess_esp', 'ptb.zip', 'mac_morpho.zip', 'knbc.zip', 'opinion_lexicon', 'toolbox', 'comtrans.zip', 'swadesh.zip', 'propbank.zip', 'mte_teip5', 'gutenberg.zip', 'product_reviews_1', 'twitter_samples.zip', 'treebank', 'state_union.zip', 'machado.zip', 'rte', 'nps_chat', 'crubadan', 'semcor.zip', 'biocreative_ppi.zip', 'ppattach', 'europarl_raw.zip', 'switchboard', 'brown_tei', 'verbnet3.zip', 'verbnet3', 'crubadan.zip', 'pil.zip', 'ycoe', 'webtext.zip', 'sentence_polarity.zip', 'timit', 'pl196x', 'nps_chat.zip', 'state_union', 'city_database.zip', 'subjectivity', 'framenet_v15', 'masc_tagged.zip', 'paradigms', 'genesis', 'gazetteers', 'twitter_samples', 'qc', 'lin_thesaurus.zip', 'udhr', 'movie_reviews.zip', 'dolch', 'problem_reports.zip', 'smultron', 'pros_cons.zip']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(nltk.data.find(\"corpora\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a_and_c.xml',\n",
       " 'dream.xml',\n",
       " 'hamlet.xml',\n",
       " 'j_caesar.xml',\n",
       " 'macbeth.xml',\n",
       " 'merchant.xml',\n",
       " 'othello.xml',\n",
       " 'r_and_j.xml']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.shakespeare.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Merchant',\n",
       " 'of',\n",
       " 'Venice',\n",
       " 'Dramatis',\n",
       " 'Personae',\n",
       " 'The',\n",
       " 'DUKE',\n",
       " 'OF',\n",
       " 'VENICE',\n",
       " '.',\n",
       " 'The',\n",
       " 'PRINCE',\n",
       " 'OF',\n",
       " 'MOROCCO',\n",
       " 'The',\n",
       " 'PRINCE',\n",
       " 'OF',\n",
       " 'ARRAGON',\n",
       " 'suitors',\n",
       " 'to',\n",
       " 'Portia',\n",
       " '.',\n",
       " 'ANTONIO',\n",
       " ',',\n",
       " 'a',\n",
       " 'merchant',\n",
       " 'of',\n",
       " 'Venice',\n",
       " '.',\n",
       " 'BASSANIO',\n",
       " ',',\n",
       " 'his',\n",
       " 'friend',\n",
       " ',',\n",
       " 'suitor',\n",
       " 'likewise',\n",
       " 'to',\n",
       " 'Portia',\n",
       " '.',\n",
       " 'SALANIO',\n",
       " 'SALARINO',\n",
       " 'GRATIANO',\n",
       " 'SALERIO',\n",
       " 'friends',\n",
       " 'to',\n",
       " 'Antonio',\n",
       " 'and',\n",
       " 'Bassanio',\n",
       " '.',\n",
       " 'LORENZO',\n",
       " ',',\n",
       " 'in',\n",
       " 'love',\n",
       " 'with',\n",
       " 'Jessica',\n",
       " '.',\n",
       " 'SHYLOCK',\n",
       " ',',\n",
       " 'a',\n",
       " 'rich',\n",
       " 'Jew',\n",
       " '.',\n",
       " 'TUBAL',\n",
       " ',',\n",
       " 'a',\n",
       " 'Jew',\n",
       " ',',\n",
       " 'his',\n",
       " 'friend',\n",
       " '.',\n",
       " 'LAUNCELOT',\n",
       " 'GOBBO',\n",
       " ',',\n",
       " 'the',\n",
       " 'clown',\n",
       " ',',\n",
       " 'servant',\n",
       " 'to',\n",
       " 'SHYLOCK',\n",
       " '.',\n",
       " 'OLD',\n",
       " 'GOBBO',\n",
       " ',',\n",
       " 'father',\n",
       " 'to',\n",
       " 'Launcelot',\n",
       " '.',\n",
       " 'LEONARDO',\n",
       " ',',\n",
       " 'servant',\n",
       " 'to',\n",
       " 'BASSANIO',\n",
       " '.',\n",
       " 'BALTHASAR',\n",
       " 'STEPHANO',\n",
       " 'servants',\n",
       " 'to',\n",
       " 'PORTIA',\n",
       " '.',\n",
       " 'PORTIA',\n",
       " ',',\n",
       " 'a',\n",
       " 'rich',\n",
       " 'heiress',\n",
       " '.',\n",
       " 'NERISSA',\n",
       " ',',\n",
       " 'her',\n",
       " 'waiting',\n",
       " '-',\n",
       " 'maid',\n",
       " '.',\n",
       " 'JESSICA',\n",
       " ',',\n",
       " 'daughter',\n",
       " 'to',\n",
       " 'SHYLOCK',\n",
       " '.',\n",
       " 'Magnificoes',\n",
       " 'of',\n",
       " 'Venice',\n",
       " ',',\n",
       " 'Officers',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Court',\n",
       " 'of',\n",
       " 'Justice',\n",
       " ',',\n",
       " 'Gaoler',\n",
       " ',',\n",
       " 'Servants',\n",
       " 'to',\n",
       " 'Portia',\n",
       " ',',\n",
       " 'and',\n",
       " 'other',\n",
       " 'Attendants',\n",
       " '.',\n",
       " 'SCENE',\n",
       " 'Partly',\n",
       " 'at',\n",
       " 'Venice',\n",
       " ',',\n",
       " 'and',\n",
       " 'partly',\n",
       " 'at',\n",
       " 'Belmont',\n",
       " ',',\n",
       " 'the',\n",
       " 'seat',\n",
       " 'of',\n",
       " 'PORTIA',\n",
       " ',',\n",
       " 'on',\n",
       " 'the',\n",
       " 'Continent',\n",
       " '.',\n",
       " 'THE',\n",
       " 'MERCHANT',\n",
       " 'OF',\n",
       " 'VENICE',\n",
       " 'ACT',\n",
       " 'I',\n",
       " 'SCENE',\n",
       " 'I',\n",
       " '.',\n",
       " 'Venice',\n",
       " '.',\n",
       " 'A',\n",
       " 'street',\n",
       " '.',\n",
       " 'Enter',\n",
       " 'ANTONIO',\n",
       " ',',\n",
       " 'SALARINO',\n",
       " ',',\n",
       " 'and',\n",
       " 'SALANIO',\n",
       " 'ANTONIO',\n",
       " 'In',\n",
       " 'sooth',\n",
       " ',',\n",
       " 'I',\n",
       " 'know',\n",
       " 'not',\n",
       " 'why',\n",
       " 'I',\n",
       " 'am',\n",
       " 'so',\n",
       " 'sad',\n",
       " ':',\n",
       " 'It',\n",
       " 'wearies',\n",
       " 'me',\n",
       " ';',\n",
       " 'you',\n",
       " 'say',\n",
       " 'it',\n",
       " 'wearies',\n",
       " 'you',\n",
       " ';',\n",
       " 'But',\n",
       " 'how',\n",
       " 'I',\n",
       " 'caught',\n",
       " 'it',\n",
       " ',',\n",
       " 'found',\n",
       " 'it',\n",
       " ',',\n",
       " 'or',\n",
       " 'came',\n",
       " 'by',\n",
       " 'it',\n",
       " ',',\n",
       " 'What',\n",
       " 'stuff',\n",
       " \"'\",\n",
       " 'tis',\n",
       " 'made',\n",
       " 'of',\n",
       " ',',\n",
       " 'whereof',\n",
       " 'it',\n",
       " 'is',\n",
       " 'born',\n",
       " ',',\n",
       " 'I',\n",
       " 'am',\n",
       " 'to',\n",
       " 'learn',\n",
       " ';',\n",
       " 'And',\n",
       " 'such',\n",
       " 'a',\n",
       " 'want',\n",
       " '-',\n",
       " 'wit',\n",
       " 'sadness',\n",
       " 'makes',\n",
       " 'of',\n",
       " 'me',\n",
       " ',',\n",
       " 'That',\n",
       " 'I',\n",
       " 'have',\n",
       " 'much',\n",
       " 'ado',\n",
       " 'to',\n",
       " 'know',\n",
       " 'myself',\n",
       " '.',\n",
       " 'SALARINO',\n",
       " 'Your',\n",
       " 'mind',\n",
       " 'is',\n",
       " 'tossing',\n",
       " 'on',\n",
       " 'the',\n",
       " 'ocean',\n",
       " ';',\n",
       " 'There',\n",
       " ',',\n",
       " 'where',\n",
       " 'your',\n",
       " 'argosies',\n",
       " 'with',\n",
       " 'portly',\n",
       " 'sail',\n",
       " ',',\n",
       " 'Like',\n",
       " 'signiors',\n",
       " 'and',\n",
       " 'rich',\n",
       " 'burghers',\n",
       " 'on',\n",
       " 'the',\n",
       " 'flood',\n",
       " ',',\n",
       " 'Or',\n",
       " ',',\n",
       " 'as',\n",
       " 'it',\n",
       " 'were',\n",
       " ',',\n",
       " 'the',\n",
       " 'pageants',\n",
       " 'of',\n",
       " 'the',\n",
       " 'sea',\n",
       " ',',\n",
       " 'Do',\n",
       " 'overpeer',\n",
       " 'the',\n",
       " 'petty',\n",
       " 'traffickers',\n",
       " ',',\n",
       " 'That',\n",
       " 'curtsy',\n",
       " 'to',\n",
       " 'them',\n",
       " ',',\n",
       " 'do',\n",
       " 'them',\n",
       " 'reverence',\n",
       " ',',\n",
       " 'As',\n",
       " 'they',\n",
       " 'fly',\n",
       " 'by',\n",
       " 'them',\n",
       " 'with',\n",
       " 'their',\n",
       " 'woven',\n",
       " 'wings',\n",
       " '.',\n",
       " 'SALANIO',\n",
       " 'Believe',\n",
       " 'me',\n",
       " ',',\n",
       " 'sir',\n",
       " ',',\n",
       " 'had',\n",
       " 'I',\n",
       " 'such',\n",
       " 'venture',\n",
       " 'forth',\n",
       " ',',\n",
       " 'The',\n",
       " 'better',\n",
       " 'part',\n",
       " 'of',\n",
       " 'my',\n",
       " 'affections',\n",
       " 'would',\n",
       " 'Be',\n",
       " 'with',\n",
       " 'my',\n",
       " 'hopes',\n",
       " 'abroad',\n",
       " '.',\n",
       " 'I',\n",
       " 'should',\n",
       " 'be',\n",
       " 'still',\n",
       " 'Plucking',\n",
       " 'the',\n",
       " 'grass',\n",
       " ',',\n",
       " 'to',\n",
       " 'know',\n",
       " 'where',\n",
       " 'sits',\n",
       " 'the',\n",
       " 'wind',\n",
       " ',',\n",
       " 'Peering',\n",
       " 'in',\n",
       " 'maps',\n",
       " 'for',\n",
       " 'ports',\n",
       " 'and',\n",
       " 'piers',\n",
       " 'and',\n",
       " 'roads',\n",
       " ';',\n",
       " 'And',\n",
       " 'every',\n",
       " 'object',\n",
       " 'that',\n",
       " 'might',\n",
       " 'make',\n",
       " 'me',\n",
       " 'fear',\n",
       " 'Misfortune',\n",
       " 'to',\n",
       " 'my',\n",
       " 'ventures',\n",
       " ',',\n",
       " 'out',\n",
       " 'of',\n",
       " 'doubt',\n",
       " 'Would',\n",
       " 'make',\n",
       " 'me',\n",
       " 'sad',\n",
       " '.',\n",
       " 'SALARINO',\n",
       " 'My',\n",
       " 'wind',\n",
       " 'cooling',\n",
       " 'my',\n",
       " 'broth',\n",
       " 'Would',\n",
       " 'blow',\n",
       " 'me',\n",
       " 'to',\n",
       " 'an',\n",
       " 'ague',\n",
       " ',',\n",
       " 'when',\n",
       " 'I',\n",
       " 'thought',\n",
       " 'What',\n",
       " 'harm',\n",
       " 'a',\n",
       " 'wind',\n",
       " 'too',\n",
       " 'great',\n",
       " 'at',\n",
       " 'sea',\n",
       " 'might',\n",
       " 'do',\n",
       " '.',\n",
       " 'I',\n",
       " 'should',\n",
       " 'not',\n",
       " 'see',\n",
       " 'the',\n",
       " 'sandy',\n",
       " 'hour',\n",
       " '-',\n",
       " 'glass',\n",
       " 'run',\n",
       " ',',\n",
       " 'But',\n",
       " 'I',\n",
       " 'should',\n",
       " 'think',\n",
       " 'of',\n",
       " 'shallows',\n",
       " 'and',\n",
       " 'of',\n",
       " 'flats',\n",
       " ',',\n",
       " 'And',\n",
       " 'see',\n",
       " 'my',\n",
       " 'wealthy',\n",
       " 'Andrew',\n",
       " 'dock',\n",
       " \"'\",\n",
       " 'd',\n",
       " 'in',\n",
       " 'sand',\n",
       " ',',\n",
       " 'Vailing',\n",
       " 'her',\n",
       " 'high',\n",
       " '-',\n",
       " 'top',\n",
       " 'lower',\n",
       " 'than',\n",
       " 'her',\n",
       " 'ribs',\n",
       " 'To',\n",
       " 'kiss',\n",
       " 'her',\n",
       " 'burial',\n",
       " '.',\n",
       " 'Should',\n",
       " 'I',\n",
       " 'go',\n",
       " 'to',\n",
       " 'church',\n",
       " 'And',\n",
       " 'see',\n",
       " 'the',\n",
       " 'holy',\n",
       " 'edifice',\n",
       " 'of',\n",
       " 'stone',\n",
       " ',',\n",
       " 'And',\n",
       " 'not',\n",
       " 'bethink',\n",
       " 'me',\n",
       " 'straight',\n",
       " 'of',\n",
       " 'dangerous',\n",
       " 'rocks',\n",
       " ',',\n",
       " 'Which',\n",
       " 'touching',\n",
       " 'but',\n",
       " 'my',\n",
       " 'gentle',\n",
       " 'vessel',\n",
       " \"'\",\n",
       " 's',\n",
       " 'side',\n",
       " ',',\n",
       " 'Would',\n",
       " 'scatter',\n",
       " 'all',\n",
       " 'her',\n",
       " 'spices',\n",
       " 'on',\n",
       " 'the',\n",
       " 'stream',\n",
       " ',',\n",
       " 'Enrobe',\n",
       " 'the',\n",
       " 'roaring',\n",
       " 'waters',\n",
       " 'with',\n",
       " 'my',\n",
       " 'silks',\n",
       " ',',\n",
       " 'And',\n",
       " ',',\n",
       " 'in',\n",
       " 'a',\n",
       " 'word',\n",
       " ',',\n",
       " 'but',\n",
       " 'even',\n",
       " 'now',\n",
       " 'worth',\n",
       " 'this',\n",
       " ',',\n",
       " 'And',\n",
       " 'now',\n",
       " 'worth',\n",
       " 'nothing',\n",
       " '?',\n",
       " 'Shall',\n",
       " 'I',\n",
       " 'have',\n",
       " 'the',\n",
       " 'thought',\n",
       " 'To',\n",
       " 'think',\n",
       " 'on',\n",
       " 'this',\n",
       " ',',\n",
       " 'and',\n",
       " 'shall',\n",
       " 'I',\n",
       " 'lack',\n",
       " 'the',\n",
       " 'thought',\n",
       " 'That',\n",
       " 'such',\n",
       " 'a',\n",
       " 'thing',\n",
       " 'bechanced',\n",
       " 'would',\n",
       " 'make',\n",
       " 'me',\n",
       " 'sad',\n",
       " '?',\n",
       " 'But',\n",
       " 'tell',\n",
       " 'not',\n",
       " 'me',\n",
       " ';',\n",
       " 'I',\n",
       " 'know',\n",
       " ',',\n",
       " 'Antonio',\n",
       " 'Is',\n",
       " 'sad',\n",
       " 'to',\n",
       " 'think',\n",
       " 'upon',\n",
       " 'his',\n",
       " 'merchandise',\n",
       " '.',\n",
       " 'ANTONIO',\n",
       " 'Believe',\n",
       " 'me',\n",
       " ',',\n",
       " 'no',\n",
       " ':',\n",
       " 'I',\n",
       " 'thank',\n",
       " 'my',\n",
       " 'fortune',\n",
       " 'for',\n",
       " 'it',\n",
       " ',',\n",
       " 'My',\n",
       " 'ventures',\n",
       " 'are',\n",
       " 'not',\n",
       " 'in',\n",
       " 'one',\n",
       " 'bottom',\n",
       " 'trusted',\n",
       " ',',\n",
       " 'Nor',\n",
       " 'to',\n",
       " 'one',\n",
       " 'place',\n",
       " ';',\n",
       " 'nor',\n",
       " 'is',\n",
       " 'my',\n",
       " 'whole',\n",
       " 'estate',\n",
       " 'Upon',\n",
       " 'the',\n",
       " 'fortune',\n",
       " 'of',\n",
       " 'this',\n",
       " 'present',\n",
       " 'year',\n",
       " ':',\n",
       " 'Therefore',\n",
       " 'my',\n",
       " 'merchandise',\n",
       " 'makes',\n",
       " 'me',\n",
       " 'not',\n",
       " 'sad',\n",
       " '.',\n",
       " 'SALARINO',\n",
       " 'Why',\n",
       " ',',\n",
       " 'then',\n",
       " 'you',\n",
       " 'are',\n",
       " 'in',\n",
       " 'love',\n",
       " '.',\n",
       " 'ANTONIO',\n",
       " 'Fie',\n",
       " ',',\n",
       " 'fie',\n",
       " '!',\n",
       " 'SALARINO',\n",
       " 'Not',\n",
       " 'in',\n",
       " 'love',\n",
       " 'neither',\n",
       " '?',\n",
       " 'Then',\n",
       " 'let',\n",
       " 'us',\n",
       " 'say',\n",
       " 'you',\n",
       " 'are',\n",
       " 'sad',\n",
       " ',',\n",
       " 'Because',\n",
       " 'you',\n",
       " 'are',\n",
       " 'not',\n",
       " 'merry',\n",
       " ':',\n",
       " 'and',\n",
       " \"'\",\n",
       " 'twere',\n",
       " 'as',\n",
       " 'easy',\n",
       " 'For',\n",
       " 'you',\n",
       " 'to',\n",
       " 'laugh',\n",
       " 'and',\n",
       " 'leap',\n",
       " 'and',\n",
       " 'say',\n",
       " 'you',\n",
       " 'are',\n",
       " 'merry',\n",
       " ',',\n",
       " 'Because',\n",
       " 'you',\n",
       " 'are',\n",
       " 'not',\n",
       " 'sad',\n",
       " '.',\n",
       " 'Now',\n",
       " ',',\n",
       " 'by',\n",
       " 'two',\n",
       " '-',\n",
       " 'headed',\n",
       " 'Janus',\n",
       " ',',\n",
       " 'Nature',\n",
       " 'hath',\n",
       " 'framed',\n",
       " 'strange',\n",
       " 'fellows',\n",
       " 'in',\n",
       " 'her',\n",
       " 'time',\n",
       " ':',\n",
       " 'Some',\n",
       " 'that',\n",
       " 'will',\n",
       " 'evermore',\n",
       " 'peep',\n",
       " 'through',\n",
       " 'their',\n",
       " 'eyes',\n",
       " 'And',\n",
       " 'laugh',\n",
       " 'like',\n",
       " 'parrots',\n",
       " 'at',\n",
       " 'a',\n",
       " 'bag',\n",
       " '-',\n",
       " 'piper',\n",
       " ',',\n",
       " 'And',\n",
       " 'other',\n",
       " 'of',\n",
       " 'such',\n",
       " 'vinegar',\n",
       " 'aspect',\n",
       " 'That',\n",
       " 'they',\n",
       " \"'\",\n",
       " 'll',\n",
       " 'not',\n",
       " 'show',\n",
       " 'their',\n",
       " 'teeth',\n",
       " 'in',\n",
       " 'way',\n",
       " 'of',\n",
       " 'smile',\n",
       " ',',\n",
       " 'Though',\n",
       " 'Nestor',\n",
       " 'swear',\n",
       " 'the',\n",
       " 'jest',\n",
       " 'be',\n",
       " 'laughable',\n",
       " '.',\n",
       " 'Enter',\n",
       " 'BASSANIO',\n",
       " ',',\n",
       " 'LORENZO',\n",
       " ',',\n",
       " 'and',\n",
       " 'GRATIANO',\n",
       " 'SALANIO',\n",
       " 'Here',\n",
       " 'comes',\n",
       " 'Bassanio',\n",
       " ',',\n",
       " 'your',\n",
       " 'most',\n",
       " 'noble',\n",
       " 'kinsman',\n",
       " ',',\n",
       " 'Gratiano',\n",
       " 'and',\n",
       " 'Lorenzo',\n",
       " '.',\n",
       " 'Fare',\n",
       " 'ye',\n",
       " 'well',\n",
       " ':',\n",
       " 'We',\n",
       " 'leave',\n",
       " 'you',\n",
       " 'now',\n",
       " 'with',\n",
       " 'better',\n",
       " 'company',\n",
       " '.',\n",
       " 'SALARINO',\n",
       " 'I',\n",
       " 'would',\n",
       " 'have',\n",
       " 'stay',\n",
       " \"'\",\n",
       " 'd',\n",
       " 'till',\n",
       " 'I',\n",
       " 'had',\n",
       " 'made',\n",
       " 'you',\n",
       " 'merry',\n",
       " ',',\n",
       " 'If',\n",
       " 'worthier',\n",
       " 'friends',\n",
       " 'had',\n",
       " 'not',\n",
       " 'prevented',\n",
       " 'me',\n",
       " '.',\n",
       " 'ANTONIO',\n",
       " 'Your',\n",
       " 'worth',\n",
       " 'is',\n",
       " 'very',\n",
       " 'dear',\n",
       " 'in',\n",
       " 'my',\n",
       " 'regard',\n",
       " '.',\n",
       " 'I',\n",
       " 'take',\n",
       " 'it',\n",
       " ',',\n",
       " 'your',\n",
       " 'own',\n",
       " 'business',\n",
       " 'calls',\n",
       " 'on',\n",
       " 'you',\n",
       " 'And',\n",
       " 'you',\n",
       " 'embrace',\n",
       " 'the',\n",
       " 'occasion',\n",
       " 'to',\n",
       " 'depart',\n",
       " '.',\n",
       " 'SALARINO',\n",
       " 'Good',\n",
       " 'morrow',\n",
       " ',',\n",
       " 'my',\n",
       " 'good',\n",
       " 'lords',\n",
       " '.',\n",
       " 'BASSANIO',\n",
       " 'Good',\n",
       " 'signiors',\n",
       " 'both',\n",
       " ',',\n",
       " 'when',\n",
       " 'shall',\n",
       " 'we',\n",
       " 'laugh',\n",
       " '?',\n",
       " 'say',\n",
       " ',',\n",
       " 'when',\n",
       " '?',\n",
       " 'You',\n",
       " 'grow',\n",
       " 'exceeding',\n",
       " 'strange',\n",
       " ':',\n",
       " 'must',\n",
       " 'it',\n",
       " 'be',\n",
       " 'so',\n",
       " '?',\n",
       " 'SALARINO',\n",
       " 'We',\n",
       " \"'\",\n",
       " 'll',\n",
       " 'make',\n",
       " 'our',\n",
       " 'leisures',\n",
       " 'to',\n",
       " 'attend',\n",
       " 'on',\n",
       " 'yours',\n",
       " '.',\n",
       " 'Exeunt',\n",
       " 'Salarino',\n",
       " 'and',\n",
       " 'Salanio',\n",
       " 'LORENZO',\n",
       " 'My',\n",
       " 'Lord',\n",
       " 'Bassanio',\n",
       " ',',\n",
       " 'since',\n",
       " 'you',\n",
       " 'have',\n",
       " 'found',\n",
       " 'Antonio',\n",
       " ',',\n",
       " 'We',\n",
       " 'two',\n",
       " 'will',\n",
       " 'leave',\n",
       " 'you',\n",
       " ':',\n",
       " 'but',\n",
       " 'at',\n",
       " 'dinner',\n",
       " '-',\n",
       " 'time',\n",
       " ',',\n",
       " 'I',\n",
       " 'pray',\n",
       " 'you',\n",
       " ',',\n",
       " 'have',\n",
       " 'in',\n",
       " 'mind',\n",
       " 'where',\n",
       " 'we',\n",
       " 'must',\n",
       " 'meet',\n",
       " '.',\n",
       " 'BASSANIO',\n",
       " 'I',\n",
       " 'will',\n",
       " 'not',\n",
       " 'fail',\n",
       " 'you',\n",
       " '.',\n",
       " 'GRATIANO',\n",
       " 'You',\n",
       " 'look',\n",
       " 'not',\n",
       " 'well',\n",
       " ',',\n",
       " 'Signior',\n",
       " 'Antonio',\n",
       " ';',\n",
       " 'You',\n",
       " 'have',\n",
       " 'too',\n",
       " 'much',\n",
       " 'respect',\n",
       " 'upon',\n",
       " 'the',\n",
       " 'world',\n",
       " ':',\n",
       " 'They',\n",
       " 'lose',\n",
       " 'it',\n",
       " 'that',\n",
       " 'do',\n",
       " 'buy',\n",
       " 'it',\n",
       " 'with',\n",
       " 'much',\n",
       " 'care',\n",
       " ':',\n",
       " 'Believe',\n",
       " 'me',\n",
       " ',',\n",
       " 'you',\n",
       " 'are',\n",
       " 'marvellously',\n",
       " 'changed',\n",
       " '.',\n",
       " 'ANTONIO',\n",
       " 'I',\n",
       " 'hold',\n",
       " 'the',\n",
       " 'world',\n",
       " 'but',\n",
       " 'as',\n",
       " 'the',\n",
       " 'world',\n",
       " ',',\n",
       " 'Gratiano',\n",
       " ';',\n",
       " 'A',\n",
       " 'stage',\n",
       " 'where',\n",
       " 'every',\n",
       " 'man',\n",
       " 'must',\n",
       " 'play',\n",
       " 'a',\n",
       " 'part',\n",
       " ',',\n",
       " 'And',\n",
       " 'mine',\n",
       " 'a',\n",
       " 'sad',\n",
       " 'one',\n",
       " '.',\n",
       " 'GRATIANO',\n",
       " 'Let',\n",
       " 'me',\n",
       " 'play',\n",
       " 'the',\n",
       " 'fool',\n",
       " ':',\n",
       " 'With',\n",
       " 'mirth',\n",
       " 'and',\n",
       " 'laughter',\n",
       " 'let',\n",
       " 'old',\n",
       " 'wrinkles',\n",
       " 'come',\n",
       " ',',\n",
       " 'And',\n",
       " 'let',\n",
       " 'my',\n",
       " 'liver',\n",
       " 'rather',\n",
       " 'heat',\n",
       " 'with',\n",
       " 'wine',\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant=nltk.corpus.shakespeare.words('merchant.xml')\n",
    "merchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Merchant of Venice Dramatis Personae The DUKE OF VENICE . The PRINCE OF MOROCCO The PRINCE OF ARRAGON suitors to Portia . ANTONIO , a merchant of Venice . BASSANIO , his friend , suitor likewise to Portia . SALANIO SALARINO GRATIANO SALERIO friends to Antonio and Bassanio . LORENZO , in love with Jessica . SHYLOCK , a rich Jew . TUBAL , a Jew , his friend . LAUNCELOT GOBBO , the clown , servant to SHYLOCK . OLD GOBBO , father to Launcelot . LEONARDO , servant to BASSANIO . BALTHASAR STEPHANO servants to PORTIA . PORTIA , a rich heiress . NERISSA , her waiting - maid . JESSICA , daughter to SHYLOCK . Magnificoes of Venice , Officers of the Court of Justice , Gaoler , Servants to Portia , and other Attendants . SCENE Partly at Venice , and partly at Belmont , the seat of PORTIA , on the Continent . THE MERCHANT OF VENICE ACT I SCENE I . Venice . A street . Enter ANTONIO , SALARINO , and SALANIO ANTONIO In sooth , I know not why I am so sad : It wearies me ; you say it wearies you ; But how I caught it , found it , or came by it , What stuff ' tis made of , whereof it is born , I am to learn ; And such a want - wit sadness makes of me , That I have much ado to know myself . SALARINO Your mind is tossing on the ocean ; There , where your argosies with portly sail , Like signiors and rich burghers on the flood , Or , as it were , the pageants of the sea , Do overpeer the petty traffickers , That curtsy to them , do them reverence , As they fly by them with their woven wings . SALANIO Believe me , sir , had I such venture forth , The better part of my affections would Be with my hopes abroad . I should be still Plucking the grass , to know where sits the wind , Peering in maps for ports and piers and roads ; And every object that might make me fear Misfortune to my ventures , out of doubt Would make me sad . SALARINO My wind cooling my broth Would blow me to an ague , when I thought What harm a wind too great at sea might do . I should not see the sandy hour - glass run , But I should think of shallows and of flats , And see my wealthy Andrew dock ' d in sand , Vailing her high - top lower than her ribs To kiss her burial . Should I go to church And see the holy edifice of stone , And not bethink me straight of dangerous rocks , Which touching but my gentle vessel ' s side , Would scatter all her spices on "
     ]
    }
   ],
   "source": [
    "for word in merchant[:500]:\n",
    "    print(word, sep=' ', end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = \"\"\"We are facing an unprecedented public health crisis, leaders are rationing critical supplies, and doctors are increasingly forced to choose who will live and who will die. With a limited number of ventilators, who gets one and who goes without? Should this patient be admitted or sent home?\n",
    "\n",
    "A simple answer to this question may be whichever patient is most urgently in need. \n",
    "\n",
    "Yet a closer look reveals a thicket of conflicting ethical considerations. \n",
    "\n",
    "\n",
    "Some patients may need a ventilator faster because of unique traits of their conditions, while others may need to continue supporting young children. Why should the rich and famous get faster access to testing? Are younger patients more deserving of a ventilator than older patients? What priority should the disabled and vulnerable have?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We',\n",
       " 'are',\n",
       " 'facing',\n",
       " 'an',\n",
       " 'unprecedented',\n",
       " 'public',\n",
       " 'health',\n",
       " 'crisis',\n",
       " ',',\n",
       " 'leaders',\n",
       " 'are',\n",
       " 'rationing',\n",
       " 'critical',\n",
       " 'supplies',\n",
       " ',',\n",
       " 'and',\n",
       " 'doctors',\n",
       " 'are',\n",
       " 'increasingly',\n",
       " 'forced',\n",
       " 'to',\n",
       " 'choose',\n",
       " 'who',\n",
       " 'will',\n",
       " 'live',\n",
       " 'and',\n",
       " 'who',\n",
       " 'will',\n",
       " 'die',\n",
       " '.',\n",
       " 'With',\n",
       " 'a',\n",
       " 'limited',\n",
       " 'number',\n",
       " 'of',\n",
       " 'ventilators',\n",
       " ',',\n",
       " 'who',\n",
       " 'gets',\n",
       " 'one',\n",
       " 'and',\n",
       " 'who',\n",
       " 'goes',\n",
       " 'without',\n",
       " '?',\n",
       " 'Should',\n",
       " 'this',\n",
       " 'patient',\n",
       " 'be',\n",
       " 'admitted',\n",
       " 'or',\n",
       " 'sent',\n",
       " 'home',\n",
       " '?',\n",
       " 'A',\n",
       " 'simple',\n",
       " 'answer',\n",
       " 'to',\n",
       " 'this',\n",
       " 'question',\n",
       " 'may',\n",
       " 'be',\n",
       " 'whichever',\n",
       " 'patient',\n",
       " 'is',\n",
       " 'most',\n",
       " 'urgently',\n",
       " 'in',\n",
       " 'need',\n",
       " '.',\n",
       " 'Yet',\n",
       " 'a',\n",
       " 'closer',\n",
       " 'look',\n",
       " 'reveals',\n",
       " 'a',\n",
       " 'thicket',\n",
       " 'of',\n",
       " 'conflicting',\n",
       " 'ethical',\n",
       " 'considerations',\n",
       " '.',\n",
       " 'Some',\n",
       " 'patients',\n",
       " 'may',\n",
       " 'need',\n",
       " 'a',\n",
       " 'ventilator',\n",
       " 'faster',\n",
       " 'because',\n",
       " 'of',\n",
       " 'unique',\n",
       " 'traits',\n",
       " 'of',\n",
       " 'their',\n",
       " 'conditions',\n",
       " ',',\n",
       " 'while',\n",
       " 'others',\n",
       " 'may',\n",
       " 'need',\n",
       " 'to',\n",
       " 'continue',\n",
       " 'supporting',\n",
       " 'young',\n",
       " 'children',\n",
       " '.',\n",
       " 'Why',\n",
       " 'should',\n",
       " 'the',\n",
       " 'rich',\n",
       " 'and',\n",
       " 'famous',\n",
       " 'get',\n",
       " 'faster',\n",
       " 'access',\n",
       " 'to',\n",
       " 'testing',\n",
       " '?',\n",
       " 'Are',\n",
       " 'younger',\n",
       " 'patients',\n",
       " 'more',\n",
       " 'deserving',\n",
       " 'of',\n",
       " 'a',\n",
       " 'ventilator',\n",
       " 'than',\n",
       " 'older',\n",
       " 'patients',\n",
       " '?',\n",
       " 'What',\n",
       " 'priority',\n",
       " 'should',\n",
       " 'the',\n",
       " 'disabled',\n",
       " 'and',\n",
       " 'vulnerable',\n",
       " 'have',\n",
       " '?']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para_tokens = word_tokenize(para)\n",
    "para_tokens\n",
    "#Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(para_tokens)\n",
    "#Number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 93 samples and 140 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FreqDist({'a': 6, 'and': 5, 'of': 5, '?': 5, 'are': 4, ',': 4, 'to': 4, 'who': 4, '.': 4, 'should': 3, ...})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist()\n",
    "for word in para_tokens:\n",
    "    fdist[word.lower()]+=1\n",
    "print(fdist)\n",
    "fdist\n",
    "#FInding word count of all word in the paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 6),\n",
       " ('and', 5),\n",
       " ('of', 5),\n",
       " ('?', 5),\n",
       " ('are', 4),\n",
       " (',', 4),\n",
       " ('to', 4),\n",
       " ('who', 4),\n",
       " ('.', 4),\n",
       " ('should', 3)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_top10 = fdist.most_common(10)\n",
    "fdist_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import blankline_tokenize\n",
    "para_blank = blankline_tokenize(para)\n",
    "len(para_blank)\n",
    "#Finds number of paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import bigrams,trigrams,ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'best',\n",
       " 'thing',\n",
       " 'is',\n",
       " 'this',\n",
       " 'world',\n",
       " 'is',\n",
       " 'biryani',\n",
       " '.',\n",
       " 'Nothing',\n",
       " 'beats',\n",
       " 'is',\n",
       " 'taste',\n",
       " ',',\n",
       " 'it',\n",
       " 'must',\n",
       " 'be',\n",
       " 'tasted',\n",
       " 'with',\n",
       " 'the',\n",
       " 'heart']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"The best thing is this world is biryani. Nothing beats is taste, it must be tasted with the heart\"\n",
    "quotes_tokens = nltk.word_tokenize(string)\n",
    "quotes_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'best'),\n",
       " ('best', 'thing'),\n",
       " ('thing', 'is'),\n",
       " ('is', 'this'),\n",
       " ('this', 'world'),\n",
       " ('world', 'is'),\n",
       " ('is', 'biryani'),\n",
       " ('biryani', '.'),\n",
       " ('.', 'Nothing'),\n",
       " ('Nothing', 'beats'),\n",
       " ('beats', 'is'),\n",
       " ('is', 'taste'),\n",
       " ('taste', ','),\n",
       " (',', 'it'),\n",
       " ('it', 'must'),\n",
       " ('must', 'be'),\n",
       " ('be', 'tasted'),\n",
       " ('tasted', 'with'),\n",
       " ('with', 'the'),\n",
       " ('the', 'heart')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_bigrams = list(nltk.bigrams(quotes_tokens))\n",
    "quotes_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'best', 'thing'),\n",
       " ('best', 'thing', 'is'),\n",
       " ('thing', 'is', 'this'),\n",
       " ('is', 'this', 'world'),\n",
       " ('this', 'world', 'is'),\n",
       " ('world', 'is', 'biryani'),\n",
       " ('is', 'biryani', '.'),\n",
       " ('biryani', '.', 'Nothing'),\n",
       " ('.', 'Nothing', 'beats'),\n",
       " ('Nothing', 'beats', 'is'),\n",
       " ('beats', 'is', 'taste'),\n",
       " ('is', 'taste', ','),\n",
       " ('taste', ',', 'it'),\n",
       " (',', 'it', 'must'),\n",
       " ('it', 'must', 'be'),\n",
       " ('must', 'be', 'tasted'),\n",
       " ('be', 'tasted', 'with'),\n",
       " ('tasted', 'with', 'the'),\n",
       " ('with', 'the', 'heart')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_trigrams = list(nltk.trigrams(quotes_tokens))\n",
    "quotes_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'best', 'thing', 'is', 'this', 'world', 'is'),\n",
       " ('best', 'thing', 'is', 'this', 'world', 'is', 'biryani'),\n",
       " ('thing', 'is', 'this', 'world', 'is', 'biryani', '.'),\n",
       " ('is', 'this', 'world', 'is', 'biryani', '.', 'Nothing'),\n",
       " ('this', 'world', 'is', 'biryani', '.', 'Nothing', 'beats'),\n",
       " ('world', 'is', 'biryani', '.', 'Nothing', 'beats', 'is'),\n",
       " ('is', 'biryani', '.', 'Nothing', 'beats', 'is', 'taste'),\n",
       " ('biryani', '.', 'Nothing', 'beats', 'is', 'taste', ','),\n",
       " ('.', 'Nothing', 'beats', 'is', 'taste', ',', 'it'),\n",
       " ('Nothing', 'beats', 'is', 'taste', ',', 'it', 'must'),\n",
       " ('beats', 'is', 'taste', ',', 'it', 'must', 'be'),\n",
       " ('is', 'taste', ',', 'it', 'must', 'be', 'tasted'),\n",
       " ('taste', ',', 'it', 'must', 'be', 'tasted', 'with'),\n",
       " (',', 'it', 'must', 'be', 'tasted', 'with', 'the'),\n",
       " ('it', 'must', 'be', 'tasted', 'with', 'the', 'heart')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_ngrams = list(nltk.ngrams(quotes_tokens, 7))\n",
    "quotes_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "pst = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ingest'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pst.stem(\"ingestation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affectation - affect\n",
      "affects - affect\n",
      "affecting - affect\n",
      "affections - affect\n",
      "affection - affect\n",
      "affected - affect\n",
      "give - give\n",
      "biryani - biryani\n",
      "Effectiveness - effect\n",
      "eating - eat\n"
     ]
    }
   ],
   "source": [
    "words_to_stem = [\"affectation\",\"affects\",\"affecting\",\"affections\",\"affection\",\"affected\",\"give\",\"biryani\",\"Effectiveness\",\"eating\"]\n",
    "for word in words_to_stem:\n",
    "    print(word+\" - \"+pst.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affectation - affect\n",
      "affects - affect\n",
      "affecting - affect\n",
      "affections - affect\n",
      "affection - affect\n",
      "affected - affect\n",
      "give - giv\n",
      "biryani - biryan\n",
      "Effectiveness - effect\n",
      "eating - eat\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "list=LancasterStemmer()\n",
    "for word in words_to_stem:\n",
    "    print(word+\" - \"+list.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "word_lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affectation - affectation\n",
      "affects - affect\n",
      "affecting - affecting\n",
      "affections - affection\n",
      "affection - affection\n",
      "affected - affected\n",
      "give - give\n",
      "biryani - biryani\n",
      "Effectiveness - Effectiveness\n",
      "eating - eating\n"
     ]
    }
   ],
   "source": [
    "for word in words_to_stem:\n",
    "    print(word+\" - \"+word_lem.lemmatize(word))\n",
    "#Without POS tags, it doesn't know what kind of a word it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corpus'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lem.lemmatize('corpora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corpora'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem('corpora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de',\n",
       " 'la',\n",
       " 'que',\n",
       " 'el',\n",
       " 'en',\n",
       " 'y',\n",
       " 'a',\n",
       " 'los',\n",
       " 'del',\n",
       " 'se',\n",
       " 'las',\n",
       " 'por',\n",
       " 'un',\n",
       " 'para',\n",
       " 'con',\n",
       " 'no',\n",
       " 'una',\n",
       " 'su',\n",
       " 'al',\n",
       " 'lo',\n",
       " 'como',\n",
       " 'más',\n",
       " 'pero',\n",
       " 'sus',\n",
       " 'le',\n",
       " 'ya',\n",
       " 'o',\n",
       " 'este',\n",
       " 'sí',\n",
       " 'porque',\n",
       " 'esta',\n",
       " 'entre',\n",
       " 'cuando',\n",
       " 'muy',\n",
       " 'sin',\n",
       " 'sobre',\n",
       " 'también',\n",
       " 'me',\n",
       " 'hasta',\n",
       " 'hay',\n",
       " 'donde',\n",
       " 'quien',\n",
       " 'desde',\n",
       " 'todo',\n",
       " 'nos',\n",
       " 'durante',\n",
       " 'todos',\n",
       " 'uno',\n",
       " 'les',\n",
       " 'ni',\n",
       " 'contra',\n",
       " 'otros',\n",
       " 'ese',\n",
       " 'eso',\n",
       " 'ante',\n",
       " 'ellos',\n",
       " 'e',\n",
       " 'esto',\n",
       " 'mí',\n",
       " 'antes',\n",
       " 'algunos',\n",
       " 'qué',\n",
       " 'unos',\n",
       " 'yo',\n",
       " 'otro',\n",
       " 'otras',\n",
       " 'otra',\n",
       " 'él',\n",
       " 'tanto',\n",
       " 'esa',\n",
       " 'estos',\n",
       " 'mucho',\n",
       " 'quienes',\n",
       " 'nada',\n",
       " 'muchos',\n",
       " 'cual',\n",
       " 'poco',\n",
       " 'ella',\n",
       " 'estar',\n",
       " 'estas',\n",
       " 'algunas',\n",
       " 'algo',\n",
       " 'nosotros',\n",
       " 'mi',\n",
       " 'mis',\n",
       " 'tú',\n",
       " 'te',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'tus',\n",
       " 'ellas',\n",
       " 'nosotras',\n",
       " 'vosotros',\n",
       " 'vosotras',\n",
       " 'os',\n",
       " 'mío',\n",
       " 'mía',\n",
       " 'míos',\n",
       " 'mías',\n",
       " 'tuyo',\n",
       " 'tuya',\n",
       " 'tuyos',\n",
       " 'tuyas',\n",
       " 'suyo',\n",
       " 'suya',\n",
       " 'suyos',\n",
       " 'suyas',\n",
       " 'nuestro',\n",
       " 'nuestra',\n",
       " 'nuestros',\n",
       " 'nuestras',\n",
       " 'vuestro',\n",
       " 'vuestra',\n",
       " 'vuestros',\n",
       " 'vuestras',\n",
       " 'esos',\n",
       " 'esas',\n",
       " 'estoy',\n",
       " 'estás',\n",
       " 'está',\n",
       " 'estamos',\n",
       " 'estáis',\n",
       " 'están',\n",
       " 'esté',\n",
       " 'estés',\n",
       " 'estemos',\n",
       " 'estéis',\n",
       " 'estén',\n",
       " 'estaré',\n",
       " 'estarás',\n",
       " 'estará',\n",
       " 'estaremos',\n",
       " 'estaréis',\n",
       " 'estarán',\n",
       " 'estaría',\n",
       " 'estarías',\n",
       " 'estaríamos',\n",
       " 'estaríais',\n",
       " 'estarían',\n",
       " 'estaba',\n",
       " 'estabas',\n",
       " 'estábamos',\n",
       " 'estabais',\n",
       " 'estaban',\n",
       " 'estuve',\n",
       " 'estuviste',\n",
       " 'estuvo',\n",
       " 'estuvimos',\n",
       " 'estuvisteis',\n",
       " 'estuvieron',\n",
       " 'estuviera',\n",
       " 'estuvieras',\n",
       " 'estuviéramos',\n",
       " 'estuvierais',\n",
       " 'estuvieran',\n",
       " 'estuviese',\n",
       " 'estuvieses',\n",
       " 'estuviésemos',\n",
       " 'estuvieseis',\n",
       " 'estuviesen',\n",
       " 'estando',\n",
       " 'estado',\n",
       " 'estada',\n",
       " 'estados',\n",
       " 'estadas',\n",
       " 'estad',\n",
       " 'he',\n",
       " 'has',\n",
       " 'ha',\n",
       " 'hemos',\n",
       " 'habéis',\n",
       " 'han',\n",
       " 'haya',\n",
       " 'hayas',\n",
       " 'hayamos',\n",
       " 'hayáis',\n",
       " 'hayan',\n",
       " 'habré',\n",
       " 'habrás',\n",
       " 'habrá',\n",
       " 'habremos',\n",
       " 'habréis',\n",
       " 'habrán',\n",
       " 'habría',\n",
       " 'habrías',\n",
       " 'habríamos',\n",
       " 'habríais',\n",
       " 'habrían',\n",
       " 'había',\n",
       " 'habías',\n",
       " 'habíamos',\n",
       " 'habíais',\n",
       " 'habían',\n",
       " 'hube',\n",
       " 'hubiste',\n",
       " 'hubo',\n",
       " 'hubimos',\n",
       " 'hubisteis',\n",
       " 'hubieron',\n",
       " 'hubiera',\n",
       " 'hubieras',\n",
       " 'hubiéramos',\n",
       " 'hubierais',\n",
       " 'hubieran',\n",
       " 'hubiese',\n",
       " 'hubieses',\n",
       " 'hubiésemos',\n",
       " 'hubieseis',\n",
       " 'hubiesen',\n",
       " 'habiendo',\n",
       " 'habido',\n",
       " 'habida',\n",
       " 'habidos',\n",
       " 'habidas',\n",
       " 'soy',\n",
       " 'eres',\n",
       " 'es',\n",
       " 'somos',\n",
       " 'sois',\n",
       " 'son',\n",
       " 'sea',\n",
       " 'seas',\n",
       " 'seamos',\n",
       " 'seáis',\n",
       " 'sean',\n",
       " 'seré',\n",
       " 'serás',\n",
       " 'será',\n",
       " 'seremos',\n",
       " 'seréis',\n",
       " 'serán',\n",
       " 'sería',\n",
       " 'serías',\n",
       " 'seríamos',\n",
       " 'seríais',\n",
       " 'serían',\n",
       " 'era',\n",
       " 'eras',\n",
       " 'éramos',\n",
       " 'erais',\n",
       " 'eran',\n",
       " 'fui',\n",
       " 'fuiste',\n",
       " 'fue',\n",
       " 'fuimos',\n",
       " 'fuisteis',\n",
       " 'fueron',\n",
       " 'fuera',\n",
       " 'fueras',\n",
       " 'fuéramos',\n",
       " 'fuerais',\n",
       " 'fueran',\n",
       " 'fuese',\n",
       " 'fueses',\n",
       " 'fuésemos',\n",
       " 'fueseis',\n",
       " 'fuesen',\n",
       " 'sintiendo',\n",
       " 'sentido',\n",
       " 'sentida',\n",
       " 'sentidos',\n",
       " 'sentidas',\n",
       " 'siente',\n",
       " 'sentid',\n",
       " 'tengo',\n",
       " 'tienes',\n",
       " 'tiene',\n",
       " 'tenemos',\n",
       " 'tenéis',\n",
       " 'tienen',\n",
       " 'tenga',\n",
       " 'tengas',\n",
       " 'tengamos',\n",
       " 'tengáis',\n",
       " 'tengan',\n",
       " 'tendré',\n",
       " 'tendrás',\n",
       " 'tendrá',\n",
       " 'tendremos',\n",
       " 'tendréis',\n",
       " 'tendrán',\n",
       " 'tendría',\n",
       " 'tendrías',\n",
       " 'tendríamos',\n",
       " 'tendríais',\n",
       " 'tendrían',\n",
       " 'tenía',\n",
       " 'tenías',\n",
       " 'teníamos',\n",
       " 'teníais',\n",
       " 'tenían',\n",
       " 'tuve',\n",
       " 'tuviste',\n",
       " 'tuvo',\n",
       " 'tuvimos',\n",
       " 'tuvisteis',\n",
       " 'tuvieron',\n",
       " 'tuviera',\n",
       " 'tuvieras',\n",
       " 'tuviéramos',\n",
       " 'tuvierais',\n",
       " 'tuvieran',\n",
       " 'tuviese',\n",
       " 'tuvieses',\n",
       " 'tuviésemos',\n",
       " 'tuvieseis',\n",
       " 'tuviesen',\n",
       " 'teniendo',\n",
       " 'tenido',\n",
       " 'tenida',\n",
       " 'tenidos',\n",
       " 'tenidas',\n",
       " 'tened']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aber',\n",
       " 'alle',\n",
       " 'allem',\n",
       " 'allen',\n",
       " 'aller',\n",
       " 'alles',\n",
       " 'als',\n",
       " 'also',\n",
       " 'am',\n",
       " 'an',\n",
       " 'ander',\n",
       " 'andere',\n",
       " 'anderem',\n",
       " 'anderen',\n",
       " 'anderer',\n",
       " 'anderes',\n",
       " 'anderm',\n",
       " 'andern',\n",
       " 'anderr',\n",
       " 'anders',\n",
       " 'auch',\n",
       " 'auf',\n",
       " 'aus',\n",
       " 'bei',\n",
       " 'bin',\n",
       " 'bis',\n",
       " 'bist',\n",
       " 'da',\n",
       " 'damit',\n",
       " 'dann',\n",
       " 'der',\n",
       " 'den',\n",
       " 'des',\n",
       " 'dem',\n",
       " 'die',\n",
       " 'das',\n",
       " 'dass',\n",
       " 'daß',\n",
       " 'derselbe',\n",
       " 'derselben',\n",
       " 'denselben',\n",
       " 'desselben',\n",
       " 'demselben',\n",
       " 'dieselbe',\n",
       " 'dieselben',\n",
       " 'dasselbe',\n",
       " 'dazu',\n",
       " 'dein',\n",
       " 'deine',\n",
       " 'deinem',\n",
       " 'deinen',\n",
       " 'deiner',\n",
       " 'deines',\n",
       " 'denn',\n",
       " 'derer',\n",
       " 'dessen',\n",
       " 'dich',\n",
       " 'dir',\n",
       " 'du',\n",
       " 'dies',\n",
       " 'diese',\n",
       " 'diesem',\n",
       " 'diesen',\n",
       " 'dieser',\n",
       " 'dieses',\n",
       " 'doch',\n",
       " 'dort',\n",
       " 'durch',\n",
       " 'ein',\n",
       " 'eine',\n",
       " 'einem',\n",
       " 'einen',\n",
       " 'einer',\n",
       " 'eines',\n",
       " 'einig',\n",
       " 'einige',\n",
       " 'einigem',\n",
       " 'einigen',\n",
       " 'einiger',\n",
       " 'einiges',\n",
       " 'einmal',\n",
       " 'er',\n",
       " 'ihn',\n",
       " 'ihm',\n",
       " 'es',\n",
       " 'etwas',\n",
       " 'euer',\n",
       " 'eure',\n",
       " 'eurem',\n",
       " 'euren',\n",
       " 'eurer',\n",
       " 'eures',\n",
       " 'für',\n",
       " 'gegen',\n",
       " 'gewesen',\n",
       " 'hab',\n",
       " 'habe',\n",
       " 'haben',\n",
       " 'hat',\n",
       " 'hatte',\n",
       " 'hatten',\n",
       " 'hier',\n",
       " 'hin',\n",
       " 'hinter',\n",
       " 'ich',\n",
       " 'mich',\n",
       " 'mir',\n",
       " 'ihr',\n",
       " 'ihre',\n",
       " 'ihrem',\n",
       " 'ihren',\n",
       " 'ihrer',\n",
       " 'ihres',\n",
       " 'euch',\n",
       " 'im',\n",
       " 'in',\n",
       " 'indem',\n",
       " 'ins',\n",
       " 'ist',\n",
       " 'jede',\n",
       " 'jedem',\n",
       " 'jeden',\n",
       " 'jeder',\n",
       " 'jedes',\n",
       " 'jene',\n",
       " 'jenem',\n",
       " 'jenen',\n",
       " 'jener',\n",
       " 'jenes',\n",
       " 'jetzt',\n",
       " 'kann',\n",
       " 'kein',\n",
       " 'keine',\n",
       " 'keinem',\n",
       " 'keinen',\n",
       " 'keiner',\n",
       " 'keines',\n",
       " 'können',\n",
       " 'könnte',\n",
       " 'machen',\n",
       " 'man',\n",
       " 'manche',\n",
       " 'manchem',\n",
       " 'manchen',\n",
       " 'mancher',\n",
       " 'manches',\n",
       " 'mein',\n",
       " 'meine',\n",
       " 'meinem',\n",
       " 'meinen',\n",
       " 'meiner',\n",
       " 'meines',\n",
       " 'mit',\n",
       " 'muss',\n",
       " 'musste',\n",
       " 'nach',\n",
       " 'nicht',\n",
       " 'nichts',\n",
       " 'noch',\n",
       " 'nun',\n",
       " 'nur',\n",
       " 'ob',\n",
       " 'oder',\n",
       " 'ohne',\n",
       " 'sehr',\n",
       " 'sein',\n",
       " 'seine',\n",
       " 'seinem',\n",
       " 'seinen',\n",
       " 'seiner',\n",
       " 'seines',\n",
       " 'selbst',\n",
       " 'sich',\n",
       " 'sie',\n",
       " 'ihnen',\n",
       " 'sind',\n",
       " 'so',\n",
       " 'solche',\n",
       " 'solchem',\n",
       " 'solchen',\n",
       " 'solcher',\n",
       " 'solches',\n",
       " 'soll',\n",
       " 'sollte',\n",
       " 'sondern',\n",
       " 'sonst',\n",
       " 'über',\n",
       " 'um',\n",
       " 'und',\n",
       " 'uns',\n",
       " 'unsere',\n",
       " 'unserem',\n",
       " 'unseren',\n",
       " 'unser',\n",
       " 'unseres',\n",
       " 'unter',\n",
       " 'viel',\n",
       " 'vom',\n",
       " 'von',\n",
       " 'vor',\n",
       " 'während',\n",
       " 'war',\n",
       " 'waren',\n",
       " 'warst',\n",
       " 'was',\n",
       " 'weg',\n",
       " 'weil',\n",
       " 'weiter',\n",
       " 'welche',\n",
       " 'welchem',\n",
       " 'welchen',\n",
       " 'welcher',\n",
       " 'welches',\n",
       " 'wenn',\n",
       " 'werde',\n",
       " 'werden',\n",
       " 'wie',\n",
       " 'wieder',\n",
       " 'will',\n",
       " 'wir',\n",
       " 'wird',\n",
       " 'wirst',\n",
       " 'wo',\n",
       " 'wollen',\n",
       " 'wollte',\n",
       " 'würde',\n",
       " 'würden',\n",
       " 'zu',\n",
       " 'zum',\n",
       " 'zur',\n",
       " 'zwar',\n",
       " 'zwischen']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('german')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 6),\n",
       " ('and', 5),\n",
       " ('of', 5),\n",
       " ('?', 5),\n",
       " ('are', 4),\n",
       " (',', 4),\n",
       " ('to', 4),\n",
       " ('who', 4),\n",
       " ('.', 4),\n",
       " ('should', 3)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_top10\n",
    "#Will have mostly stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "punctuation = re.compile(r'[=,?!,:;,[0-9]]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_punctuation = []\n",
    "for words in para:\n",
    "    word = punctuation.sub(\"\",words)\n",
    "    if len(word)>0:\n",
    "        post_punctuation.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['W',\n",
       " 'e',\n",
       " ' ',\n",
       " 'a',\n",
       " 'r',\n",
       " 'e',\n",
       " ' ',\n",
       " 'f',\n",
       " 'a',\n",
       " 'c',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " ' ',\n",
       " 'a',\n",
       " 'n',\n",
       " ' ',\n",
       " 'u',\n",
       " 'n',\n",
       " 'p',\n",
       " 'r',\n",
       " 'e',\n",
       " 'c',\n",
       " 'e',\n",
       " 'd',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " 'e',\n",
       " 'd',\n",
       " ' ',\n",
       " 'p',\n",
       " 'u',\n",
       " 'b',\n",
       " 'l',\n",
       " 'i',\n",
       " 'c',\n",
       " ' ',\n",
       " 'h',\n",
       " 'e',\n",
       " 'a',\n",
       " 'l',\n",
       " 't',\n",
       " 'h',\n",
       " ' ',\n",
       " 'c',\n",
       " 'r',\n",
       " 'i',\n",
       " 's',\n",
       " 'i',\n",
       " 's',\n",
       " ',',\n",
       " ' ',\n",
       " 'l',\n",
       " 'e',\n",
       " 'a',\n",
       " 'd',\n",
       " 'e',\n",
       " 'r',\n",
       " 's',\n",
       " ' ',\n",
       " 'a',\n",
       " 'r',\n",
       " 'e',\n",
       " ' ',\n",
       " 'r',\n",
       " 'a',\n",
       " 't',\n",
       " 'i',\n",
       " 'o',\n",
       " 'n',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " ' ',\n",
       " 'c',\n",
       " 'r',\n",
       " 'i',\n",
       " 't',\n",
       " 'i',\n",
       " 'c',\n",
       " 'a',\n",
       " 'l',\n",
       " ' ',\n",
       " 's',\n",
       " 'u',\n",
       " 'p',\n",
       " 'p',\n",
       " 'l',\n",
       " 'i',\n",
       " 'e',\n",
       " 's',\n",
       " ',',\n",
       " ' ',\n",
       " 'a',\n",
       " 'n',\n",
       " 'd',\n",
       " ' ',\n",
       " 'd',\n",
       " 'o',\n",
       " 'c',\n",
       " 't',\n",
       " 'o',\n",
       " 'r',\n",
       " 's',\n",
       " ' ',\n",
       " 'a',\n",
       " 'r',\n",
       " 'e',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " 'c',\n",
       " 'r',\n",
       " 'e',\n",
       " 'a',\n",
       " 's',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " 'l',\n",
       " 'y',\n",
       " ' ',\n",
       " 'f',\n",
       " 'o',\n",
       " 'r',\n",
       " 'c',\n",
       " 'e',\n",
       " 'd',\n",
       " ' ',\n",
       " 't',\n",
       " 'o',\n",
       " ' ',\n",
       " 'c',\n",
       " 'h',\n",
       " 'o',\n",
       " 'o',\n",
       " 's',\n",
       " 'e',\n",
       " ' ',\n",
       " 'w',\n",
       " 'h',\n",
       " 'o',\n",
       " ' ',\n",
       " 'w',\n",
       " 'i',\n",
       " 'l',\n",
       " 'l',\n",
       " ' ',\n",
       " 'l',\n",
       " 'i',\n",
       " 'v',\n",
       " 'e',\n",
       " ' ',\n",
       " 'a',\n",
       " 'n',\n",
       " 'd',\n",
       " ' ',\n",
       " 'w',\n",
       " 'h',\n",
       " 'o',\n",
       " ' ',\n",
       " 'w',\n",
       " 'i',\n",
       " 'l',\n",
       " 'l',\n",
       " ' ',\n",
       " 'd',\n",
       " 'i',\n",
       " 'e',\n",
       " '.',\n",
       " ' ',\n",
       " 'W',\n",
       " 'i',\n",
       " 't',\n",
       " 'h',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'l',\n",
       " 'i',\n",
       " 'm',\n",
       " 'i',\n",
       " 't',\n",
       " 'e',\n",
       " 'd',\n",
       " ' ',\n",
       " 'n',\n",
       " 'u',\n",
       " 'm',\n",
       " 'b',\n",
       " 'e',\n",
       " 'r',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " ' ',\n",
       " 'v',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " 'i',\n",
       " 'l',\n",
       " 'a',\n",
       " 't',\n",
       " 'o',\n",
       " 'r',\n",
       " 's',\n",
       " ',',\n",
       " ' ',\n",
       " 'w',\n",
       " 'h',\n",
       " 'o',\n",
       " ' ',\n",
       " 'g',\n",
       " 'e',\n",
       " 't',\n",
       " 's',\n",
       " ' ',\n",
       " 'o',\n",
       " 'n',\n",
       " 'e',\n",
       " ' ',\n",
       " 'a',\n",
       " 'n',\n",
       " 'd',\n",
       " ' ',\n",
       " 'w',\n",
       " 'h',\n",
       " 'o',\n",
       " ' ',\n",
       " 'g',\n",
       " 'o',\n",
       " 'e',\n",
       " 's',\n",
       " ' ',\n",
       " 'w',\n",
       " 'i',\n",
       " 't',\n",
       " 'h',\n",
       " 'o',\n",
       " 'u',\n",
       " 't',\n",
       " '?',\n",
       " ' ',\n",
       " 'S',\n",
       " 'h',\n",
       " 'o',\n",
       " 'u',\n",
       " 'l',\n",
       " 'd',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'p',\n",
       " 'a',\n",
       " 't',\n",
       " 'i',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " ' ',\n",
       " 'b',\n",
       " 'e',\n",
       " ' ',\n",
       " 'a',\n",
       " 'd',\n",
       " 'm',\n",
       " 'i',\n",
       " 't',\n",
       " 't',\n",
       " 'e',\n",
       " 'd',\n",
       " ' ',\n",
       " 'o',\n",
       " 'r',\n",
       " ' ',\n",
       " 's',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " ' ',\n",
       " 'h',\n",
       " 'o',\n",
       " 'm',\n",
       " 'e',\n",
       " '?',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'A',\n",
       " ' ',\n",
       " 's',\n",
       " 'i',\n",
       " 'm',\n",
       " 'p',\n",
       " 'l',\n",
       " 'e',\n",
       " ' ',\n",
       " 'a',\n",
       " 'n',\n",
       " 's',\n",
       " 'w',\n",
       " 'e',\n",
       " 'r',\n",
       " ' ',\n",
       " 't',\n",
       " 'o',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'q',\n",
       " 'u',\n",
       " 'e',\n",
       " 's',\n",
       " 't',\n",
       " 'i',\n",
       " 'o',\n",
       " 'n',\n",
       " ' ',\n",
       " 'm',\n",
       " 'a',\n",
       " 'y',\n",
       " ' ',\n",
       " 'b',\n",
       " 'e',\n",
       " ' ',\n",
       " 'w',\n",
       " 'h',\n",
       " 'i',\n",
       " 'c',\n",
       " 'h',\n",
       " 'e',\n",
       " 'v',\n",
       " 'e',\n",
       " 'r',\n",
       " ' ',\n",
       " 'p',\n",
       " 'a',\n",
       " 't',\n",
       " 'i',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " ' ',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'm',\n",
       " 'o',\n",
       " 's',\n",
       " 't',\n",
       " ' ',\n",
       " 'u',\n",
       " 'r',\n",
       " 'g',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " 'l',\n",
       " 'y',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " ' ',\n",
       " 'n',\n",
       " 'e',\n",
       " 'e',\n",
       " 'd',\n",
       " '.',\n",
       " ' ',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Y',\n",
       " 'e',\n",
       " 't',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'c',\n",
       " 'l',\n",
       " 'o',\n",
       " 's',\n",
       " 'e',\n",
       " 'r',\n",
       " ' ',\n",
       " 'l',\n",
       " 'o',\n",
       " 'o',\n",
       " 'k',\n",
       " ' ',\n",
       " 'r',\n",
       " 'e',\n",
       " 'v',\n",
       " 'e',\n",
       " 'a',\n",
       " 'l',\n",
       " 's',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'i',\n",
       " 'c',\n",
       " 'k',\n",
       " 'e',\n",
       " 't',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " ' ',\n",
       " 'c',\n",
       " 'o',\n",
       " 'n',\n",
       " 'f',\n",
       " 'l',\n",
       " 'i',\n",
       " 'c',\n",
       " 't',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " ' ',\n",
       " 'e',\n",
       " 't',\n",
       " 'h',\n",
       " 'i',\n",
       " 'c',\n",
       " 'a',\n",
       " 'l',\n",
       " ' ',\n",
       " 'c',\n",
       " 'o',\n",
       " 'n',\n",
       " 's',\n",
       " 'i',\n",
       " 'd',\n",
       " 'e',\n",
       " 'r',\n",
       " 'a',\n",
       " 't',\n",
       " 'i',\n",
       " 'o',\n",
       " 'n',\n",
       " 's',\n",
       " '.',\n",
       " ' ',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'S',\n",
       " 'o',\n",
       " 'm',\n",
       " 'e',\n",
       " ' ',\n",
       " 'p',\n",
       " 'a',\n",
       " 't',\n",
       " 'i',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " 's',\n",
       " ' ',\n",
       " 'm',\n",
       " 'a',\n",
       " 'y',\n",
       " ' ',\n",
       " 'n',\n",
       " 'e',\n",
       " 'e',\n",
       " 'd',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'v',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " 'i',\n",
       " 'l',\n",
       " 'a',\n",
       " 't',\n",
       " 'o',\n",
       " 'r',\n",
       " ' ',\n",
       " 'f',\n",
       " 'a',\n",
       " 's',\n",
       " 't',\n",
       " 'e',\n",
       " 'r',\n",
       " ' ',\n",
       " 'b',\n",
       " 'e',\n",
       " 'c',\n",
       " 'a',\n",
       " 'u',\n",
       " 's',\n",
       " 'e',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " ' ',\n",
       " 'u',\n",
       " 'n',\n",
       " 'i',\n",
       " 'q',\n",
       " 'u',\n",
       " 'e',\n",
       " ' ',\n",
       " 't',\n",
       " 'r',\n",
       " 'a',\n",
       " 'i',\n",
       " 't',\n",
       " 's',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " 'i',\n",
       " 'r',\n",
       " ' ',\n",
       " 'c',\n",
       " 'o',\n",
       " 'n',\n",
       " 'd',\n",
       " 'i',\n",
       " 't',\n",
       " 'i',\n",
       " 'o',\n",
       " 'n',\n",
       " 's',\n",
       " ',',\n",
       " ' ',\n",
       " 'w',\n",
       " 'h',\n",
       " 'i',\n",
       " 'l',\n",
       " 'e',\n",
       " ' ',\n",
       " 'o',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " 'r',\n",
       " 's',\n",
       " ' ',\n",
       " 'm',\n",
       " 'a',\n",
       " 'y',\n",
       " ' ',\n",
       " 'n',\n",
       " 'e',\n",
       " 'e',\n",
       " 'd',\n",
       " ' ',\n",
       " 't',\n",
       " 'o',\n",
       " ' ',\n",
       " 'c',\n",
       " 'o',\n",
       " 'n',\n",
       " 't',\n",
       " 'i',\n",
       " 'n',\n",
       " 'u',\n",
       " 'e',\n",
       " ' ',\n",
       " 's',\n",
       " 'u',\n",
       " 'p',\n",
       " 'p',\n",
       " 'o',\n",
       " 'r',\n",
       " 't',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " ' ',\n",
       " 'y',\n",
       " 'o',\n",
       " 'u',\n",
       " 'n',\n",
       " 'g',\n",
       " ' ',\n",
       " 'c',\n",
       " 'h',\n",
       " 'i',\n",
       " 'l',\n",
       " 'd',\n",
       " 'r',\n",
       " 'e',\n",
       " 'n',\n",
       " '.',\n",
       " ' ',\n",
       " 'W',\n",
       " 'h',\n",
       " 'y',\n",
       " ' ',\n",
       " 's',\n",
       " 'h',\n",
       " 'o',\n",
       " 'u',\n",
       " 'l',\n",
       " 'd',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'r',\n",
       " 'i',\n",
       " 'c',\n",
       " 'h',\n",
       " ' ',\n",
       " 'a',\n",
       " 'n',\n",
       " 'd',\n",
       " ' ',\n",
       " 'f',\n",
       " 'a',\n",
       " 'm',\n",
       " 'o',\n",
       " 'u',\n",
       " 's',\n",
       " ' ',\n",
       " 'g',\n",
       " 'e',\n",
       " 't',\n",
       " ' ',\n",
       " 'f',\n",
       " 'a',\n",
       " 's',\n",
       " 't',\n",
       " 'e',\n",
       " 'r',\n",
       " ' ',\n",
       " 'a',\n",
       " 'c',\n",
       " 'c',\n",
       " 'e',\n",
       " 's',\n",
       " 's',\n",
       " ' ',\n",
       " 't',\n",
       " 'o',\n",
       " ' ',\n",
       " 't',\n",
       " 'e',\n",
       " 's',\n",
       " 't',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " '?',\n",
       " ' ',\n",
       " 'A',\n",
       " 'r',\n",
       " 'e',\n",
       " ' ',\n",
       " 'y',\n",
       " 'o',\n",
       " 'u',\n",
       " 'n',\n",
       " 'g',\n",
       " 'e',\n",
       " 'r',\n",
       " ' ',\n",
       " 'p',\n",
       " 'a',\n",
       " 't',\n",
       " 'i',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " 's',\n",
       " ' ',\n",
       " 'm',\n",
       " 'o',\n",
       " 'r',\n",
       " 'e',\n",
       " ' ',\n",
       " 'd',\n",
       " 'e',\n",
       " 's',\n",
       " 'e',\n",
       " 'r',\n",
       " 'v',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'v',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " 'i',\n",
       " 'l',\n",
       " 'a',\n",
       " 't',\n",
       " 'o',\n",
       " 'r',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'a',\n",
       " 'n',\n",
       " ' ',\n",
       " 'o',\n",
       " 'l',\n",
       " 'd',\n",
       " 'e',\n",
       " 'r',\n",
       " ' ',\n",
       " 'p',\n",
       " 'a',\n",
       " 't',\n",
       " 'i',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " 's',\n",
       " '?',\n",
       " ' ',\n",
       " 'W',\n",
       " 'h',\n",
       " 'a',\n",
       " 't',\n",
       " ' ',\n",
       " 'p',\n",
       " 'r',\n",
       " 'i',\n",
       " 'o',\n",
       " 'r',\n",
       " 'i',\n",
       " 't',\n",
       " 'y',\n",
       " ' ',\n",
       " 's',\n",
       " 'h',\n",
       " 'o',\n",
       " 'u',\n",
       " 'l',\n",
       " 'd',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'd',\n",
       " 'i',\n",
       " 's',\n",
       " 'a',\n",
       " 'b',\n",
       " 'l',\n",
       " 'e',\n",
       " 'd',\n",
       " ' ',\n",
       " 'a',\n",
       " 'n',\n",
       " 'd',\n",
       " ' ',\n",
       " 'v',\n",
       " 'u',\n",
       " 'l',\n",
       " 'n',\n",
       " 'e',\n",
       " 'r',\n",
       " 'a',\n",
       " 'b',\n",
       " 'l',\n",
       " 'e',\n",
       " ' ',\n",
       " 'h',\n",
       " 'a',\n",
       " 'v',\n",
       " 'e',\n",
       " '?',\n",
       " '\\n']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "795"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(post_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'a', 'natural', 'when', 'it', 'comes', 'to', 'eating', 'biryani']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"I am a natural when it comes to eating biryani\"\n",
    "sent_tokens = word_tokenize(sent)\n",
    "sent_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP')]\n",
      "[('am', 'VBP')]\n",
      "[('a', 'DT')]\n",
      "[('natural', 'JJ')]\n",
      "[('when', 'WRB')]\n",
      "[('it', 'PRP')]\n",
      "[('comes', 'VBZ')]\n",
      "[('to', 'TO')]\n",
      "[('eating', 'VBG')]\n",
      "[('biryani', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "for token in sent_tokens:\n",
    "    print(nltk.pos_tag([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ne_sent = \"The President of USA, Donald Trump, stays in the White House\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "NE_tokens = word_tokenize(Ne_sent)\n",
    "NE_tags = nltk.pos_tag(NE_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  The/DT\n",
      "  President/NNP\n",
      "  of/IN\n",
      "  (ORGANIZATION USA/NNP)\n",
      "  ,/,\n",
      "  (PERSON Donald/NNP Trump/NNP)\n",
      "  ,/,\n",
      "  stays/VBZ\n",
      "  in/IN\n",
      "  the/DT\n",
      "  (FACILITY White/NNP House/NNP))\n"
     ]
    }
   ],
   "source": [
    "#POS Tags\n",
    "NE_NER = ne_chunk(NE_tags)\n",
    "print(NE_NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('angry', 'JJ'),\n",
       " ('leopard', 'NN'),\n",
       " ('ate', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('little', 'JJ'),\n",
       " ('baby', 'NN'),\n",
       " ('who', 'WP'),\n",
       " ('was', 'VBD'),\n",
       " ('after', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('marshmallow', 'NN')]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunkd = \"The angry leopard ate the little baby who was after a marshmallow\"\n",
    "chunkd_tokens = nltk.pos_tag(word_tokenize(chunkd))\n",
    "chunkd_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_np = r\"NP: {<DT>?<JJ>*<NN>}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunkd_parser = nltk.RegexpParser(grammar_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
